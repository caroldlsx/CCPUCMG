{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bad9pShDz1Fg"
      },
      "source": [
        "## **PROCESSAMENTO E ANÁLISE DE IMAGENS - TRABALHO PRÁTICO**\n",
        "**Aluna:** Carolina Lima\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9noIkXV86Owz"
      },
      "source": [
        "#*Introdução*\n",
        "A classificação automática e precisa de frutas é uma tarefa um tanto quanto desafiadora, especialmente quando há semelhanças entre algumas variedades, como maçãs, peras e pêssegos. Neste contexto, foram escolhidos dois métodos baseados em redes neurais convolucionais para reconhecimento e classificação automática de frutas para serem avaliados em função de sua precisão, acurácia e tempo.\n",
        "Em seguida, um terceiro método foi proposto visando melhorias no tempo de treinamento e mantendo a acurácia.\n",
        "\n",
        "#*Base de dados*\n",
        "A base de dados escolhida consiste em um conjunto de imagens de diferentes variedades de frutas, acompanhadas de rótulos ou etiquetas que indicam a qual categoria cada imagem pertence (por exemplo: maçã, laranja, banana, etc.). Essas imagens foram capturadas em ambientes variados e podem incluir variações de ângulo, iluminação e tamanho. A fim de reconhecer automaticamente e classificar diferentes tipos de frutas com base em características visuais extraídas das imagens, esse conjunto de dados foi utilizado para treinar os algoritmos presentes neste trabalho. Você pode encontrar o dataset utilizado  neste [link](https://drive.google.com/drive/folders/1e-mxCW6vBm9RrST9yctB8R8UHm1RnB4H?usp=sharing).\n",
        "\n",
        "\n",
        "#*Vídeo explicando o código:* [link](https://youtu.be/5O4QoLhojUY)\n",
        "\n",
        "#*Apresentação: [link](https://drive.google.com/file/d/12TTb0j1hQkVg6zETPb4ru9lsD90qAq2z/view?usp=sharing)*\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLA6Ve921fL1"
      },
      "source": [
        "#**Conexão com o Google Drive**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miL9U1JJ-a6S"
      },
      "source": [
        "Esse trecho de código importa a função 'drive' do módulo 'google.colab' e monta o Google Drive no ambiente de trabalho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwcuBlPd1to1",
        "outputId": "29fb5a06-6b08-4a0d-b580-5f7b935be5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_54YIs4c198F"
      },
      "source": [
        "#**Bibliotecas utilizadas em ambos os classificadores**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAQIH9PT1fL7"
      },
      "source": [
        "Abaixo, importamos todas as bibliotecas necessárias para rodar o projeto.\n",
        "\n",
        "**Descrição de cada importação:**\n",
        "\n",
        "1. **import os:** fornece uma maneira de interagir com o sistema operacional, permitindo a manipulação de caminhos de arquivo, execução de comandos do sistema e outras operações relacionadas ao sistema operacional.\n",
        "\n",
        "2. **import PIL:** é usada para manipulação e processamento de imagens em Python. Ela oferece várias funcionalidades para abrir, editar e salvar imagens, bem como para realizar operações de processamento de imagem.\n",
        "\n",
        "3. **import random:** fornece funções para geração de números aleatórios em Python. Ele é comumente usado para embaralhar listas, selecionar itens aleatórios de uma sequência e realizar outras operações que envolvam aleatoriedade.\n",
        "\n",
        "4. **import pathlib:** fornece classes e funções para manipulação de caminhos de arquivo e diretório em uma maneira orientada a objetos. Ele facilita a criação, manipulação e navegação em caminhos de forma mais legível e portável.\n",
        "\n",
        "5. **import numpy as np:** fornece suporte para arrays multidimensionais e funções matemáticas de alto desempenho, tornando-o essencial para a manipulação e análise de dados numéricos.\n",
        "\n",
        "6. **import pandas as pd:** usada para análise e manipulação de dados em Python. Ela oferece estruturas de dados poderosas, como o DataFrame, e funções para carregar, limpar, transformar e analisar dados de forma eficiente.\n",
        "\n",
        "7. **import seaborn as sns:** biblioteca de visualização de dados em Python baseada no matplotlib. Ele fornece uma interface de alto nível para criar gráficos estatísticos atraentes e informativos.\n",
        "\n",
        "8. **import tensorflow as tf:** biblioteca popular de aprendizado de máquina e deep learning em Python. O tensorflow é importado como tf para facilitar o uso de suas funções e classes.\n",
        "\n",
        "9. **import matplotlib.pyplot as plt:** fornece funções para criação de gráficos e visualizações em Python. Ela é amplamente utilizada para criar gráficos de linha, gráficos de dispersão, histogramas, gráficos de barras e muitos outros tipos de gráficos.\n",
        "\n",
        "10. **import matplotlib.image as mpimg:** módulo que fornece funções para ler, exibir e salvar imagens usando a biblioteca matplotlib.\n",
        "\n",
        "11. **from tensorflow import keras:** API de alto nível para construir e treinar modelos de aprendizado de máquina e deep learning. Ele é importado do pacote tensorflow para facilitar o uso das funções e classes do keras.\n",
        "\n",
        "12. **from tensorflow.keras import layers:** módulo do keras que contém várias camadas comuns usadas na construção de modelos de redes neurais.\n",
        "\n",
        "13. **from tensorflow.keras.models import Sequential:** lasse do keras que permite construir modelos de redes neurais sequenciais, onde as camadas são empilhadas uma após a outra.\n",
        "\n",
        "14. **from sklearn.model_selection import train_test_split:** A função train_test_split do sklearn é usada para dividir conjuntos de dados em subconjuntos de treinamento e teste. É comumente usada para avaliar o desempenho de modelos de aprendizado de máquina.\n",
        "\n",
        "15. **from tensorflow.keras.utils import load_img, img_to_array:** As funções load_img e img_to_array do keras.utils são usadas para carregar imagens de arquivos e converter imagens em arrays numpy, respectivamente.\n",
        "\n",
        "16. **from tensorflow.keras.preprocessing.image import ImageDataGenerator:** A classe ImageDataGenerator do keras.preprocessing.image é usada para criar instâncias de geradores de dados de imagem que podem aumentar, redimensionar, normalizar e pré-processar imagens para treinamento de modelos de aprendizado de máquina.\n",
        "\n",
        "17. **from tensorflow.keras.models import load_model:** a importação da função load_model permite carregar um modelo previamente salvo em um arquivo. Essa função é útil quando você deseja carregar um modelo treinado e usá-lo para fazer previsões ou continuar o treinamento.\n",
        "\n",
        "18. **from tensorflow.keras import layers:** a importação da classe layers permite acessar diversas camadas disponíveis no TensorFlow Keras. Essas camadas são usadas para construir modelos de redes neurais, incluindo camadas convolucionais, de pooling, de ativação, de dropout, entre outras.\n",
        "\n",
        "19. **from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D:** esas importações são comumente usadas na construção de modelos de CNNs para processamento de imagens. Elas fornecem funcionalidades essenciais para carregar, pré-processar e processar imagens, além de permitir a definição de camadas específicas usadas em redes neurais convolucionais.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDWXHesKlJkU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PIL\n",
        "import time\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaudomgbFXFh"
      },
      "source": [
        "#**Classificador A: Criação e treinamento do modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwqbNUN520JU"
      },
      "outputs": [],
      "source": [
        "# definine o caminho do diretório onde as imagens de treinamento estão localizadas\n",
        "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/dataset/train\")\n",
        "\n",
        "# conta o número total de imagens no diretório de treinamento\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "\n",
        "print(image_count)\n",
        "\n",
        "# cria uma lista de caminhos para as imagens de uma categoria específica\n",
        "apricot = list(data_dir.glob('Peach/*'))\n",
        "\n",
        "# abre a primeira imagem da lista apricot usando a biblioteca PIL\n",
        "PIL.Image.open(str(apricot[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwu31MkqCZIv"
      },
      "outputs": [],
      "source": [
        "# define o número de amostras que serão processadas em cada iteração durante o treinamento do modelo\n",
        "batch_size = 32\n",
        "\n",
        "#\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "\"\"\"\n",
        "Essa função lê as imagens do diretório (data_dir) e gera um conjunto de dados TensorFlow com base na estrutura de pastas\n",
        "\n",
        "Args:\n",
        "    validation_split: indica que 20% dos dados serão reservados para validação\n",
        "    subset:           especifica que estamos criando um conjunto de dados para treinamento\n",
        "    seed:             define uma semente para garantir a reprodutibilidade dos resultados\n",
        "    image_size:       define o tamanho das imagens após o redimensionamento.\n",
        "    batch_size:       define o tamanho do lote para o conjunto de treinamento\n",
        "\n",
        "Returns:\n",
        "    retorna um objeto tf.data.Dataset que contém os dados de treinamento do conjunto de imagens\n",
        "\"\"\"\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "\"\"\"\n",
        "Essa função lê as imagens do diretório (data_dir) e gera um conjunto de dados TensorFlow com base na estrutura de pastas\n",
        "\n",
        "Args:\n",
        "    validation_split: indica que 20% dos dados serão reservados para validação\n",
        "    subset:           especifica que estamos criando um conjunto de dados para treinamento\n",
        "    seed:             define uma semente para garantir a reprodutibilidade dos resultados\n",
        "    image_size:       define o tamanho das imagens após o redimensionamento.\n",
        "    batch_size:       define o tamanho do lote para o conjunto de treinamento\n",
        "\n",
        "Returns:\n",
        "    retorna um objeto tf.data.Dataset que contém os dados de validação do conjunto de imagens\n",
        "\"\"\"\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "# contém uma lista de nomes de classe associados às categorias das imagens no conjunto de dados de treinamento train_ds\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGnTmoC6DJtQ"
      },
      "outputs": [],
      "source": [
        "# estabelece o valor AUTOTUNE como uma constante especial fornecida pela biblioteca TensorFlow para otimizar o desempenho do carregamento de dados\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "\"\"\"\n",
        "As variáveis train_ds e val_ds estão sendo modificadas para aplicar algumas transformações.\n",
        "Primeiro, o método cache() é chamado para armazenar em cache os dados do conjunto de treinamento\n",
        "em memória, o que pode acelerar o carregamento subsequente dos dados.\n",
        "Em seguida, o método shuffle(1000) é aplicado para embaralhar os exemplos de treinamento aleatoriamente,\n",
        "com um tamanho de buffer de embaralhamento de 1000.\n",
        "Por fim, o método prefetch(buffer_size=AUTOTUNE) é usado para pré-carregar os dados em um buffer,\n",
        "permitindo uma sobreposição de processamento entre a obtenção dos dados e o treinamento do modelo.\n",
        "\"\"\"\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\"\"\"\n",
        "É criada uma camada de normalização usando a classe Rescaling do TensorFlow.\n",
        "Essa camada será usada para normalizar os valores dos pixels das imagens,\n",
        "dividindo-os por 255, o que resulta em valores no intervalo [0, 1].\n",
        "\"\"\"\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "\n",
        "# aplica a camada de normalização às imagens de entrada, normalizando seus valores de pixel\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "\"\"\"\n",
        "É criado um iterador para a variável normalized_ds usando a função iter(), e em seguida,\n",
        "o método next() é aplicado para obter um único lote de imagens e rótulos do conjunto de dados normalizado.\n",
        "\"\"\"\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "\n",
        "# seleciona a primeira imagem do lote\n",
        "first_image = image_batch[0]\n",
        "\n",
        "\n",
        "# print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iWqgliBDT0g"
      },
      "outputs": [],
      "source": [
        "# número de classes ou categorias diferentes nas quais as imagens devem ser classificadas\n",
        "num_classes = 33\n",
        "\n",
        "\"\"\"\n",
        "Cria uma sequência de camadas para aplicar técnicas de aumento de dados nas imagens de treinamento\n",
        "aplicando transformações aleatórias, como virar, girar, traduzir e ajustar o contraste das imagens.\n",
        "\n",
        "Args:\n",
        "    layers.RandomFlip():        faz um flip vertical aleatório nas imagens de entrada.\n",
        "                                Ela recebe as dimensões da imagem de entrada (altura, largura, canais) e,\n",
        "                                durante o treinamento, aleatoriamente decide se deve ou não aplicar o flip vertical.\n",
        "    layers.RandomFlip():        faz um flip horizontal aleatório nas imagens de entrada.\n",
        "                                Assim como a camada anterior, ela decide aleatoriamente durante o treinamento se\n",
        "                                deve ou não aplicar o flip horizontal.\n",
        "    layers.RandomTranslation(): faz uma translação aleatória nas imagens de entrada. Ela recebe fatores de translação\n",
        "                                para a altura e largura, que determinam o intervalo no qual as imagens serão transladadas.\n",
        "    layers.RandomRotation():    faz uma rotação aleatória nas imagens de entrada. O argumento factor especifica o intervalo\n",
        "                                em que as imagens serão rotacionadas, em radianos. Durante o treinamento, a camada decide\n",
        "                                aleatoriamente a quantidade de rotação a ser aplicada.\n",
        "   layers.RandomContrast():     faz um ajuste aleatório no contraste das imagens de entrada. O argumento factor especifica o\n",
        "                                intervalo de ajuste do contraste. Durante o treinamento, a camada decide aleatoriamente\n",
        "                                o fator de ajuste a ser aplicado.\n",
        "\n",
        " Returns:                       objeto 'Sequential' que representa a sequência de camadas de aumento de dados no modelo.\n",
        "\"\"\"\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"vertical\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), fill_mode=\"reflect\"),\n",
        "    layers.RandomRotation(factor=(-0.2, 0.2)),\n",
        "    layers.RandomContrast(factor=[1.0, 3.0], seed=123 )\n",
        "\n",
        "  ]\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Um modelo de rede neural é definido utilizando a API Sequencial do Keras.\n",
        "Ele é construído em camadas, onde cada camada é adicionada sequencialmente ao modelo.\n",
        "\n",
        "Args:\n",
        "    data_augmentation:         camada de pré-processamento que aplica uma série de transformações de aumento de dados às imagens\n",
        "    layers.Rescaling():        camada de normalização que dimensiona os valores dos pixels das imagens de entrada para o intervalo [0, 1].\n",
        "    layers.Conv2D():           camada convolucional com 16 filtros de tamanho 3x3.\n",
        "    layers.MaxPooling2D():     camada de pooling que realiza a operação de pooling máximo para reduzir a dimensão espacial das saídas da camada convolucional.\n",
        "    layers.Dropout():          camada de dropout que desativa aleatoriamente uma fração de 40% dos neurônios de entrada durante o treinamento.\n",
        "    layers.Flatten():          camada que transforma os mapas de características 2D em um vetor 1D, permitindo a transição das camadas convolucionais para as camadas densas.\n",
        "    layers.Dense():            camada densa com 128 neurônios e função de ativação sigmoidal.\n",
        "    layers.Dense():            camada de saída do modelo, com um número de neurônios igual ao número de classes do problema.\n",
        "\n",
        "Returns: Um modelo de rede neural convolucional\n",
        "\"\"\"\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  # relu introduz a não linearidade\n",
        "  # padding=same A opção padding='same' faz com que o preenchimento seja adicionado às bordas da imagem para manter o tamanho da saída igual ao tamanho da entrada\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.4),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.4),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='sigmoid'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8j-qPllEvBG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Define um objeto de otimizador usando o algoritmo RMSprop\n",
        "\n",
        "Args:\n",
        "    learning_rate: taxa de aprendizado que controla o tamanho dos passos que o otimizador toma durante o treinamento. É um valor positivo geralmente na faixa de 0.001 a 0.1.\n",
        "    rho:           valor de decaimento (decay) do RMSprop. Fator que controla a média móvel exponencial das estimativas do segundo momento do gradiente. É um valor entre 0 e 1.\n",
        "    momentum:      valor que acelera o processo de treinamento, adicionando um momento aos gradientes calculados. É um valor entre 0 e 1.\n",
        "    epsilon:       pequeno valor adicionado ao denominador para estabilidade numérica. Geralmente é um valor como 1e-07.\n",
        "    centered:      booleano que indica se a média do gradiente deve ser subtraída. Quando definido como True, a média é subtraída; quando definido como False, apenas a média móvel exponencial é usada.\n",
        "    name:          nome do otimizador.\n",
        "\n",
        "Returns:           objeto de otimizador que será usado para otimizar o modelo durante o treinamento\n",
        "\"\"\"\n",
        "optimizer = tf.keras.optimizers.legacy.RMSprop(\n",
        "    learning_rate=0.0005,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    name=\"RMSprop\",\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "A função model.compile() é usada para configurar o modelo para o treinamento, especificando o otimizador, a função de perda e as métricas a serem utilizadas durante o treinamento e a avaliação\n",
        "Args:\n",
        "    optimizer: objeto optimizer definidoo anteriormente (RMSprop).\n",
        "    loss:      função de perda CategoricalCrossentropy, que é a função apropriada para problemas de classificação com múltiplas classes.\n",
        "    metrics:   métrica de acurácia.\n",
        "\n",
        "Returns:\n",
        "    Após chamar model.compile(), o modelo está pronto para ser treinado usando o método model.fit().\n",
        "\"\"\"\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# resumo do modelo, mostrado a arquitetura da rede neural e o número de parâmetros treináveis em cada camada\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS9tCtCDEyAE"
      },
      "outputs": [],
      "source": [
        "# marca o início do tempo de execução do treinamento\n",
        "inicio = time.time()\n",
        "\n",
        "# número de épocas de treinamento\n",
        "epochs=10\n",
        "\n",
        "\"\"\"\n",
        " Executa o treinamento do modelo.\n",
        " Ele recebe o conjunto de treinamento (train_ds) e o conjunto de validação (val_ds) como entrada,\n",
        " além de especificar o tamanho do lote (batch_size) e o número de épocas (epochs).\n",
        "\"\"\"\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  batch_size = 32,\n",
        "  epochs=epochs\n",
        ")\n",
        "\n",
        "# marca o fim do tempo de execução do treinamento\n",
        "fim = time.time()\n",
        "\n",
        "# calcula e imprime a duração total do treinamento em segundos\n",
        "print(fim - inicio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hE2LUJpgAX8"
      },
      "source": [
        "#**Classificador A: Plot de gráfico**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e3corV3fv9l"
      },
      "outputs": [],
      "source": [
        "# gráfico para verificar precisão e perda do modelo\n",
        "pd.DataFrame(history_1.history).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2OVontviyYe"
      },
      "source": [
        "#**Classificador A: Testes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUnkmzarl5Gt"
      },
      "source": [
        "*teste 1*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nto37kzME0pY"
      },
      "outputs": [],
      "source": [
        "# carrega uma imagem específica localizada no caminho referente às imagens para teste\n",
        "sample_path = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/dataset/test/5233.jpg\")\n",
        "\n",
        "\"\"\"\n",
        "Função tf.keras.utils.load_img() para carregar um objeto 'Image' do PIL\n",
        "\n",
        "Args:\n",
        "    sample_path: caminho onde a imagem está localizada\n",
        "    target_size: redimensiona a imagem para um tamanho específico\n",
        "    img_height e img_width: dimensões especificadas.\n",
        "\n",
        "Returns:\n",
        "    Objeto 'Image' do PIL contendo a imagem carregada e redimensionada.\n",
        "\"\"\"\n",
        "img = tf.keras.utils.load_img(\n",
        "    sample_path, target_size=(img_height, img_width)\n",
        ")\n",
        "\n",
        "# converte o objeto em img em um array numpy\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "\n",
        "# expande as dimensões do array, adicionando uma nova dimensão no índice 0\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "# faz previsões usando o modelo treinado em uma img_array\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# calcula as probabilidades associadas às previsões feitas pelo modelo\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "# exibe a classe prevista para a imagem e a confiança associada a essa previsão\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")\n",
        "\n",
        "# carrega e exibe a imagem localizada no caminho especificado\n",
        "PIL.Image.open(sample_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUo_GjULl9HD"
      },
      "source": [
        "*teste 2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5ZnBW4BE2tO"
      },
      "outputs": [],
      "source": [
        "sample_path = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/dataset/test/5021.jpg\")\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sample_path, target_size=(img_height, img_width)\n",
        ")\n",
        "\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-sxr_DBE39Q"
      },
      "source": [
        "*teste 3*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3GBZpMfE4D1"
      },
      "outputs": [],
      "source": [
        "sample_path = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/dataset/test/4882.jpg\")\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sample_path, target_size=(img_height, img_width)\n",
        ")\n",
        "\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classificador B: Criação e treinamento do modelo**"
      ],
      "metadata": {
        "id": "mrgLQG1D9jCR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN5Dnp5WJVia"
      },
      "outputs": [],
      "source": [
        "# definine o caminho do diretório onde as imagens de treinamento estão localizadas\n",
        "trainDirectory = '/content/drive/MyDrive/Colab Notebooks/dataset/train'\n",
        "\n",
        "imageHeight = 100\n",
        "imageWidth = 100\n",
        "thickness = 3\n",
        "inputShape = (imageHeight, imageWidth, thickness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIOHfqJ5Jhiv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Aplicação de técnicas de aumento de imagem para aumentar a variabilidade dos dados de treinamento,\n",
        "o que pode ajudar a melhorar o desempenho do modelo e sua capacidade de generalização\n",
        "\n",
        "Args:\n",
        "    rescale:            redimensiona os valores dos pixels das imagens dividindo-os por 255, normalizando-os para a faixa [0, 1].\n",
        "    vertical_flip:      inverte as imagens verticalmente.\n",
        "    horizontal_flip:    inverte as imagens horizontalmente.\n",
        "    rotation_range:     rotaciona aleatoriamente as imagens dentro da faixa especificada (em graus).\n",
        "    width_shift_range:  desloca aleatoriamente a largura (direção horizontal) das imagens por uma fração da largura total.\n",
        "    height_shift_range: desloca aleatoriamente a altura (direção vertical) das imagens por uma fração da altura total.\n",
        "    zoom_range:         aplica zoom aleatoriamente nas imagens por um fator especificado.\n",
        "    validation_split:   especifica a fração dos dados a serem utilizados para validação.\n",
        "\"\"\"\n",
        "imageDataGenerator = ImageDataGenerator(rescale=1./255,\n",
        "                                vertical_flip=True,\n",
        "                                horizontal_flip=True,\n",
        "                                rotation_range=40,\n",
        "                                width_shift_range=0.2,\n",
        "                                height_shift_range=0.2,\n",
        "                                zoom_range=0.1,\n",
        "                                validation_split=0.2)\n",
        "\n",
        "# redimensiona os valores de pixel para ficar entre 0 e 1 usando rescale=1./255\n",
        "testDataGenerator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\"\"\"\n",
        "Flow_from_directory() é um método das classes ImageDataGenerator e DirectoryIterator na biblioteca Keras para carregar\n",
        "aumentar dados de imagem de um diretório durante o treinamento ou previsão do modelo.\n",
        "Args:\n",
        "    diretório:   caminho para o diretório que contém as imagens.\n",
        "    target_size: tamanho para o qual as imagens devem ser redimensionadas.\n",
        "    color_mode:  modo de cor das imagens ('rgb' ou 'grayscale').\n",
        "    batch_size:  número de imagens em cada lote.\n",
        "    shuffle:     se deseja embaralhar a ordem das imagens.\n",
        "    class_mode:  tipo de rótulo a ser usado ('categorical', 'binary', 'sparse' ou None).\n",
        "    subconjunto: se deve carregar um subconjunto das imagens ('treinamento' ou 'validação').\n",
        "\"\"\"\n",
        "\n",
        "trainGenerator = imageDataGenerator.flow_from_directory(trainDirectory,\n",
        "                                                 shuffle=True,\n",
        "                                                 batch_size=32,\n",
        "                                                 subset='training',\n",
        "                                                 target_size=(100, 100))\n",
        "\n",
        "validGenerator = imageDataGenerator.flow_from_directory(trainDirectory,\n",
        "                                                 shuffle=True,\n",
        "                                                 batch_size=16,\n",
        "                                                 subset='validation',\n",
        "                                                 target_size=(100, 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elYlLfJnJkJM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Este código define um modelo de rede neural convolucional usando a classe Sequential do Keras.\n",
        "\n",
        "Estrutura:\n",
        "  Duas camadas convolucionais com 64 filtros cada, função de ativação ReLU e tamanho do filtro 5x5.\n",
        "  Uma camada de pooling com tamanho de pool 2x2 para reduzir a dimensionalidade.\n",
        "  Uma camada de dropout com taxa de 25% para regularização.\n",
        "  Duas camadas convolucionais com 128 filtros cada, função de ativação ReLU e tamanho do filtro 3x3.\n",
        "  Uma camada de pooling com tamanho de pool 2x2 e stride 2x2 para reduzir a dimensionalidade.\n",
        "  Uma camada de dropout com taxa de 25% para regularização.\n",
        "  Uma camada de achatamento para converter os mapas de características em um vetor unidimensional.\n",
        "  Uma camada densa (totalmente conectada) com 256 unidades e função de ativação ReLU.\n",
        "  Uma camada de dropout com taxa de 50% para regularização.\n",
        "  Uma camada densa de saída com 33 unidades (correspondendo ao número de classes) e função de ativação softmax para classificação multiclasse.\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (5, 5), activation='relu', padding='Same', input_shape=inputShape))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu', padding='Same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='Same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='Same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(33, activation='softmax'))\n",
        "\n",
        "# o modelo é compilado com a função de perda \"categorical_crossentropy\", otimizador Adam com taxa de aprendizado 1e-4 e métricas de avaliação de precisão.\n",
        "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])\n",
        "\n",
        "# exibe um resumo da arquitetura do modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "876S_lDXJmV7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O código cria um objeto EarlyStopping que é um retorno de chamada (callback) do Keras. Esse retorno de chamada é usado durante o treinamento do modelo para interromper\n",
        "o treinamento prematuramente se determinadas condições não forem atendidas.\n",
        "\n",
        "Args:\n",
        "    monitor:              indica a métrica a ser monitorada durante o treinamento, no caso, a acurácia da validação.\n",
        "    patience:             especifica o número de épocas que o treinamento pode continuar sem melhorias na métrica monitorada antes de parar.\n",
        "    mode':                indica se o objetivo é maximizar ou minimizar a métrica monitorada. Neste caso, como se trata de uma acurácia, o objetivo é maximizá-la.\n",
        "    restore_best_weights: indica se os melhores pesos do modelo devem ser restaurados após o treinamento, com base na melhor época de validação.\n",
        "\"\"\"\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, mode='max',\n",
        "                                     restore_best_weights=True)\n",
        "\n",
        "\"\"\"\n",
        "Realiza o treinamento do modelo utilizando os geradores de dados trainGenerator e validGenerator.\n",
        "Ele utiliza o método fit do modelo para ajustar os pesos com base nos dados de treinamento\n",
        "e avaliar o desempenho nos dados de validação.\n",
        "\n",
        "Args:\n",
        "    trainGenerator:   gerador de dados para o treinamento.\n",
        "    validation_data:  gerador de dados para a validação.\n",
        "    steps_per_epoch:  número de passos (batches) por época durante o treinamento, que é calculado dividindo o número total de amostras de treinamento pelo tamanho do lote (batch size).\n",
        "    validation_steps: número de passos (batches) por época durante a validação, que é calculado dividindo o número total de amostras de validação pelo tamanho do lote (batch size).\n",
        "    callbacks:        lista de retornos de chamada (callbacks) a serem aplicados durante o treinamento, neste caso, apenas o retorno de chamada early definido anteriormente.\n",
        "    epochs:           número de épocas de treinamento.\n",
        "\n",
        "    O histórico do treinamento é armazenado na variável history\n",
        "\"\"\"\n",
        "\n",
        "history = model.fit(trainGenerator, validation_data=validGenerator,\n",
        "                   steps_per_epoch=trainGenerator.n//trainGenerator.batch_size,\n",
        "                    validation_steps=validGenerator.n//validGenerator.batch_size,\n",
        "                    callbacks=[early],\n",
        "                   epochs=12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YSZ5lB-8Jnqg"
      },
      "outputs": [],
      "source": [
        "# salva o modelo treinado em um arquivo\n",
        "model.save('model_CNN_saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fmyWwAdtJolK"
      },
      "outputs": [],
      "source": [
        "# carrega o modelo salvo\n",
        "model = load_model('model_CNN_saved')\n",
        "\n",
        "\"\"\"\n",
        "# cria um dicionário chamado fruitMap que mapeia os rótulos de classe codificados\n",
        "com inteiros usados ​​no conjunto de dados de treinamento para seus nomes de frutas correspondentes.\n",
        "# isso é feito iterando sobre o atributo class_indices do objeto trainGenerator, que é um dicionário\n",
        "que mapeia os nomes de classe de string para seus rótulos codificados por números inteiros.\n",
        "\"\"\"\n",
        "fruitMap = dict([(v, k) for k, v in trainGenerator.class_indices.items()])\n",
        "fruitMap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gRvnljDPJrFK"
      },
      "outputs": [],
      "source": [
        "# aplica a função softmax às previsões de saída do modelo CNN pré-treinado\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classificador B: Plot de gráfico**"
      ],
      "metadata": {
        "id": "bhcjRBFHIogE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotando os dados para ver a precisão e perda do modelo\n",
        "\n",
        "pd.DataFrame(history_1.history).plot()"
      ],
      "metadata": {
        "id": "aguzzlFYKKVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classificador B: Testes**"
      ],
      "metadata": {
        "id": "fYTze4Ql9rNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*teste 1*"
      ],
      "metadata": {
        "id": "Tox-iLRSJncb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oBEBtRTCJqBF"
      },
      "outputs": [],
      "source": [
        "# carrega imagem do sistema de arquivos\n",
        "samplePath = pathlib.Path(\"../input/fruit-recognition/test/test/5021.jpg\")\n",
        "\n",
        "# carrega uma imagem do caminho especificado em samplePath e redimensiona a imagem para o tamanho de (100, 100). A imagem carregada é retornada como um objeto do tipo PIL.Image.Image\n",
        "image = tf.keras.preprocessing.image.load_img(\n",
        "    samplePath, target_size=(100, 100)\n",
        ")\n",
        "\n",
        "# exibe a imagem usando a função imshow()\n",
        "plt.imshow(image)\n",
        "\n",
        "# converte a imagem em array e normaliza os valores de pixel entre 0 e 1 usando a divisão por 255\n",
        "image = np.array(image)\n",
        "image = image / 255.0\n",
        "\n",
        "# contém a imagem remodelada como um array numpy com as dimensões (1, imageWidth, imageHeight, 3)\n",
        "image = image.reshape(1,imageWidth,imageHeight, 3)\n",
        "\n",
        "# faz uma previsão na imagem de entrada usando a função predict()\n",
        "# a saída de predict() é um array de probabilidades de classes previstas, onde cada elemento do array corresponde a um rótulo de classe diferente\n",
        "predictions = model.predict(image)\n",
        "predictions\n",
        "\n",
        "# printa o rótulo da classe predita e a pontuação de confiança correspondente para a imagem de entrada, usando a matriz de pontuação obtida da função softmax aplicada às probabilidades da classe predita\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(\"This image is {} with a {:.2f} %\".format(fruitMap[np.argmax(score)],100 * np.max(predictions)))\n",
        "\n",
        "\n",
        "#np.argmax(): retorna o índice do elemento máximo no array de pontuações que corresponde à classe prevista com a maior probabilidade\n",
        "#np.max():    retorna o valor máximo de probabilidade no array de previsões\n",
        "#             fornece o score de confiança para a classe prevista, multiplicando o valor máximo de probabilidade por 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*teste 2*"
      ],
      "metadata": {
        "id": "77TaA8XiJdK-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W3oLuyNHJtvw"
      },
      "outputs": [],
      "source": [
        "samplePath = pathlib.Path(\"../input/fruit-recognition/test/test/4882.jpg\")\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(\n",
        "    samplePath, target_size=(100, 100)\n",
        ")\n",
        "\n",
        "plt.imshow(image)\n",
        "\n",
        "image = np.array(image)\n",
        "image = image / 255.0\n",
        "\n",
        "image = image.reshape(1,imageWidth,imageHeight, 3)\n",
        "\n",
        "predictions = model.predict(image)\n",
        "predictions\n",
        "\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(\"This image is {} with a {:.2f} %\".format(fruitMap[np.argmax(score)],100 * np.max(predictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*teste 3*"
      ],
      "metadata": {
        "id": "5E2MYRiu-ijE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samplePath = pathlib.Path(\"../input/fruit-recognition/test/test/5233.jpg\")\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(\n",
        "    samplePath, target_size=(100, 100)\n",
        ")\n",
        "\n",
        "plt.imshow(image)\n",
        "\n",
        "image = np.array(image)\n",
        "image = image / 255.0\n",
        "\n",
        "image = image.reshape(1,imageWidth,imageHeight, 3)\n",
        "\n",
        "predictions = model.predict(image)\n",
        "predictions\n",
        "\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(\"This image is {} with a {:.2f} %\".format(fruitMap[np.argmax(score)],100 * np.max(predictions)))"
      ],
      "metadata": {
        "id": "yTT423dO-nyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Nova cnnC**"
      ],
      "metadata": {
        "id": "nwg16w4Li_l0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIBRZh6JGZCW"
      },
      "outputs": [],
      "source": [
        "# número de classes ou categorias diferentes nas quais as imagens devem ser classificadas\n",
        "num_classes = 33\n",
        "\n",
        "\"\"\"\n",
        "Modelo de rede neural convolucional simples composta por várias camadas\n",
        "\n",
        "    Camada Conv2D:    Tem 5 filtros (ou canais) e um tamanho de kernel de 3x3. Aplica a função de ativação ReLU aos mapas de recursos resultantes. Essa camada é responsável por extrair características das imagens de entrada.\n",
        "    Camada MaxPool2D: Realiza a operação de max pooling com um pool size de 2x2. Reduz a dimensionalidade dos mapas de recursos, mantendo as características mais proeminentes.\n",
        "    Camada Flatten:   Transforma os mapas de recursos 2D em um vetor 1D. Prepara os dados para a próxima camada totalmente conectada.\n",
        "    Camada Dense:     É uma camada totalmente conectada que mapeia o vetor 1D de entrada para a quantidade de classes no conjunto de dados (representado por len(class_names)). Usa a função de ativação softmax para gerar probabilidades de cada classe.\n",
        "\n",
        "Returns: Um modelo de rede neural convolucional\n",
        "\"\"\"\n",
        "md = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=5,\n",
        "                          kernel_size = 3,\n",
        "                          activation = \"relu\",\n",
        "                          input_shape = (100,100,3)),\n",
        "    tf.keras.layers.MaxPool2D(pool_size =2,\n",
        "                             padding='valid'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(len(class_names), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "'''\n",
        "Define as configurações de compilação para o modelo.\n",
        "\n",
        "  loss:      A função de perda utilizada durante o treinamento é a categorical cross-entropy.\n",
        "  optimizer: O otimizador escolhido para ajustar os pesos do modelo durante o treinamento é o Adam.\n",
        "  metrics:   A métrica de desempenho escolhida para avaliar o modelo durante o treinamento é a acurácia.\n",
        "'''\n",
        "md.compile(loss=\"categorical_crossentropy\",\n",
        "               optimizer = tf.keras.optimizers.Adam(),\n",
        "               metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfi0WBXTH7HA"
      },
      "outputs": [],
      "source": [
        "md.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABocSB9UIYTD"
      },
      "outputs": [],
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, mode='max',\n",
        "                                     restore_best_weights=True)\n",
        "epochs=5\n",
        "\n",
        "inicio = time.time()\n",
        "\n",
        "# faz o fit do modelo nos dados de treinamento\n",
        "history_1 = md.fit(train_ds,\n",
        "                       epochs =5,\n",
        "                       validation_data= val_ds)\n",
        "fim = time.time()\n",
        "\n",
        "print(fim - inicio)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **cnnC: Testes**"
      ],
      "metadata": {
        "id": "Fk3NZ_ULYz9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*teste 1*"
      ],
      "metadata": {
        "id": "k4816aNW5tgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carrega imagem do sistema de arquivos\n",
        "samplePath = pathlib.Path(\"../input/fruit-recognition/test/test/0083.jpg\")\n",
        "\n",
        "# carrega uma imagem do caminho especificado em samplePath e redimensiona a imagem para o tamanho de (100, 100). A imagem carregada é retornada como um objeto do tipo PIL.Image.Image\n",
        "image = tf.keras.preprocessing.image.load_img(\n",
        "    samplePath, target_size=(100, 100)\n",
        ")\n",
        "\n",
        "# exibe a imagem usando a função imshow()\n",
        "plt.imshow(image)\n",
        "\n",
        "# converte a imagem em array e normaliza os valores de pixel entre 0 e 1 usando a divisão por 255\n",
        "image = np.array(image)\n",
        "image = image / 255.0\n",
        "\n",
        "# contém a imagem remodelada como um array numpy com as dimensões (1, imageWidth, imageHeight, 3)\n",
        "image = image.reshape(1,imageWidth,imageHeight, 3)\n",
        "\n",
        "# faz uma previsão na imagem de entrada usando a função predict()\n",
        "# a saída de predict() é um array de probabilidades de classes previstas, onde cada elemento do array corresponde a um rótulo de classe diferente\n",
        "predictions = model.predict(image)\n",
        "predictions\n",
        "\n",
        "# printa o rótulo da classe predita e a pontuação de confiança correspondente para a imagem de entrada, usando a matriz de pontuação obtida da função softmax aplicada às probabilidades da classe predita\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(\"This image is {} with a {:.2f} %\".format(fruitMap[np.argmax(score)],100 * np.max(predictions)))\n",
        "\n",
        "\n",
        "#np.argmax(): retorna o índice do elemento máximo no array de pontuações que corresponde à classe prevista com a maior probabilidade\n",
        "#np.max():    retorna o valor máximo de probabilidade no array de previsões\n",
        "#             fornece o score de confiança para a classe prevista, multiplicando o valor máximo de probabilidade por 100"
      ],
      "metadata": {
        "id": "hBuS3rIs5sKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*teste 2*"
      ],
      "metadata": {
        "id": "TKR_XMfO50LI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carrega imagem do sistema de arquivos\n",
        "samplePath = pathlib.Path(\"../input/fruit-recognition/test/test/0001.jpg\")\n",
        "\n",
        "# carrega uma imagem do caminho especificado em samplePath e redimensiona a imagem para o tamanho de (100, 100). A imagem carregada é retornada como um objeto do tipo PIL.Image.Image\n",
        "image = tf.keras.preprocessing.image.load_img(\n",
        "    samplePath, target_size=(100, 100)\n",
        ")\n",
        "\n",
        "# exibe a imagem usando a função imshow()\n",
        "plt.imshow(image)\n",
        "\n",
        "# converte a imagem em array e normaliza os valores de pixel entre 0 e 1 usando a divisão por 255\n",
        "image = np.array(image)\n",
        "image = image / 255.0\n",
        "\n",
        "# contém a imagem remodelada como um array numpy com as dimensões (1, imageWidth, imageHeight, 3)\n",
        "image = image.reshape(1,imageWidth,imageHeight, 3)\n",
        "\n",
        "# faz uma previsão na imagem de entrada usando a função predict()\n",
        "# a saída de predict() é um array de probabilidades de classes previstas, onde cada elemento do array corresponde a um rótulo de classe diferente\n",
        "predictions = model.predict(image)\n",
        "predictions\n",
        "\n",
        "# printa o rótulo da classe predita e a pontuação de confiança correspondente para a imagem de entrada, usando a matriz de pontuação obtida da função softmax aplicada às probabilidades da classe predita\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(\"This image is {} with a {:.2f} %\".format(fruitMap[np.argmax(score)],100 * np.max(predictions)))\n",
        "\n",
        "\n",
        "#np.argmax(): retorna o índice do elemento máximo no array de pontuações que corresponde à classe prevista com a maior probabilidade\n",
        "#np.max():    retorna o valor máximo de probabilidade no array de previsões\n",
        "#             fornece o score de confiança para a classe prevista, multiplicando o valor máximo de probabilidade por 100"
      ],
      "metadata": {
        "id": "OGJ1eGN552IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*teste 3*"
      ],
      "metadata": {
        "id": "W1qS4zMp52vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carrega imagem do sistema de arquivos\n",
        "samplePath = pathlib.Path(\"../input/fruit-recognition/test/test/0010.jpg\")\n",
        "\n",
        "# carrega uma imagem do caminho especificado em samplePath e redimensiona a imagem para o tamanho de (100, 100). A imagem carregada é retornada como um objeto do tipo PIL.Image.Image\n",
        "image = tf.keras.preprocessing.image.load_img(\n",
        "    samplePath, target_size=(100, 100)\n",
        ")\n",
        "\n",
        "# exibe a imagem usando a função imshow()\n",
        "plt.imshow(image)\n",
        "\n",
        "# converte a imagem em array e normaliza os valores de pixel entre 0 e 1 usando a divisão por 255\n",
        "image = np.array(image)\n",
        "image = image / 255.0\n",
        "\n",
        "# contém a imagem remodelada como um array numpy com as dimensões (1, imageWidth, imageHeight, 3)\n",
        "image = image.reshape(1,imageWidth,imageHeight, 3)\n",
        "\n",
        "# faz uma previsão na imagem de entrada usando a função predict()\n",
        "# a saída de predict() é um array de probabilidades de classes previstas, onde cada elemento do array corresponde a um rótulo de classe diferente\n",
        "predictions = model.predict(image)\n",
        "predictions\n",
        "\n",
        "# printa o rótulo da classe predita e a pontuação de confiança correspondente para a imagem de entrada, usando a matriz de pontuação obtida da função softmax aplicada às probabilidades da classe predita\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(\"This image is {} with a {:.2f} %\".format(fruitMap[np.argmax(score)],100 * np.max(predictions)))\n",
        "\n",
        "\n",
        "#np.argmax(): retorna o índice do elemento máximo no array de pontuações que corresponde à classe prevista com a maior probabilidade\n",
        "#np.max():    retorna o valor máximo de probabilidade no array de previsões\n",
        "#             fornece o score de confiança para a classe prevista, multiplicando o valor máximo de probabilidade por 100"
      ],
      "metadata": {
        "id": "e-xrG3YK54I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **cnnC: Plot de gráfico**"
      ],
      "metadata": {
        "id": "IbxhoAr-YruX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotando os dados para ver a precisão e perda do modelo\n",
        "pd.DataFrame(history_1.history).plot()"
      ],
      "metadata": {
        "id": "2qRIp43uYzT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}